{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e90cbc9-ef44-41c9-a1bc-7deb3ae6fad0",
   "metadata": {},
   "source": [
    "# Last Number Revisited with a Hidden Layer\n",
    "\n",
    "Let's redo our last number example, now with a hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f6667e-3c47-435c-ab10-a1d1b36ae347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b392c06a-bf77-477b-b995-0225ac081794",
   "metadata": {},
   "source": [
    "Our data class is the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069c5af4-e079-45b9-ace1-3ee77cff59a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelDataCategorical:\n",
    "    \"\"\"this is the model data for our \"last number\" training set.  We\n",
    "    produce input of length N, consisting of numbers 0-9 and store\n",
    "    the result in a 10-element array as categorical data.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, N=10):\n",
    "        self.N = N\n",
    "        \n",
    "        # our model input data\n",
    "        self.x = np.random.randint(0, high=10, size=N)\n",
    "        self.x_scaled = self.x / 10\n",
    "        \n",
    "        # our scaled model output data\n",
    "        self.y = np.array([self.x[-1]])\n",
    "        self.y_scaled = np.zeros(10) + 0.01\n",
    "        self.y_scaled[self.x[-1]] = 0.99\n",
    "        \n",
    "    def interpret_result(self, out):\n",
    "        \"\"\"take the network output and return the number we predict\"\"\"\n",
    "        return np.argmax(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf95dc8-78b2-4ef2-86cd-4f5f4882b2e3",
   "metadata": {},
   "source": [
    "Now our network will store an additional array, $B$, and take the size of the\n",
    "hidden layer as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc8eb917-91e9-4656-82ce-302f4a97213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"A neural network class with a single hidden layer.\"\"\"\n",
    "\n",
    "    def __init__(self, num_training_unique=100,\n",
    "                 data_class=None, hidden_layer_size=20):\n",
    "\n",
    "        self.num_training_unique = num_training_unique\n",
    "\n",
    "        self.train_set = []\n",
    "        for _ in range(self.num_training_unique):\n",
    "            self.train_set.append(data_class())\n",
    "\n",
    "        # initialize our matrix with Gaussian normal random numbers\n",
    "        # we get the size from the length of the input and output\n",
    "        model = self.train_set[0]\n",
    "        self.N_out = len(model.y_scaled)\n",
    "        self.N_in = len(model.x_scaled)\n",
    "        self.N_hidden = hidden_layer_size\n",
    "\n",
    "        # we will initialize the weights with Gaussian normal random\n",
    "        # numbers centered on 0 with a width of 1/sqrt(n), where n is\n",
    "        # the length of the input state\n",
    "\n",
    "        # A is the set of weights between the hidden layer and output layer\n",
    "        self.A = np.random.normal(0.0, 1.0/np.sqrt(self.N_hidden), (self.N_out, self.N_hidden))\n",
    "\n",
    "        # B is the set of weights between the input layer and hidden layer\n",
    "        self.B = np.random.normal(0.0, 1.0/np.sqrt(self.N_in), (self.N_hidden, self.N_in))\n",
    "\n",
    "    def g(self, xi):\n",
    "        \"\"\"our sigmoid function that operates on the layers\"\"\"\n",
    "        return 1.0/(1.0 + np.exp(-xi))\n",
    "\n",
    "    def train(self, n_epochs=10, eta=0.2):\n",
    "        \"\"\"Train the neural network by doing gradient descent with back\n",
    "        propagation to set the matrix elements in B (the weights\n",
    "        between the input and hidden layer) and A (the weights between\n",
    "        the hidden layer and output layer)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(n_epochs):\n",
    "            random.shuffle(self.train_set)\n",
    "            for model in self.train_set:\n",
    "\n",
    "                # make the input and output data column vectors\n",
    "                x = model.x_scaled.reshape(self.N_in, 1)\n",
    "                y = model.y_scaled.reshape(self.N_out, 1)\n",
    "\n",
    "                # propagate the input through the network\n",
    "                z_tilde = self.g(self.B @ x)\n",
    "                z = self.g(self.A @ z_tilde)\n",
    "\n",
    "                # compute the errors (backpropagate to the hidden layer)\n",
    "                e = z - y\n",
    "                e_tilde = self.A.T @ e\n",
    "\n",
    "                # corrections\n",
    "                dA = -2 * eta * e * z * (1 - z) @ z_tilde.T\n",
    "                dB = -2 * eta * e_tilde * z_tilde * (1 - z_tilde) @ x.T\n",
    "\n",
    "                self.A[:, :] += dA\n",
    "                self.B[:, :] += dB\n",
    "\n",
    "    def predict(self, model):\n",
    "        \"\"\" predict the outcome using our trained matrix A \"\"\"\n",
    "        z = self.g(self.A @ (self.g(self.B @ model.x_scaled)))\n",
    "        return model.interpret_result(z)\n",
    "    \n",
    "    def check_accuracy(self):\n",
    "        \"\"\"use the trained network on the training data and return\n",
    "        the fraction we get correct\"\"\"\n",
    "        \n",
    "        n_right = 0\n",
    "        for model in self.train_set:\n",
    "            y_nn = self.predict(model)\n",
    "            if y_nn == model.y:\n",
    "                n_right += 1\n",
    "        return n_right / len(self.train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "549c37b4-3f4d-4e7f-bef7-317ba775ee72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(num_training_unique=1000,\n",
    "                   hidden_layer_size=20, data_class=ModelDataCategorical)\n",
    "nn.train(n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebd36487-81d3-40b3-84fc-16613be82c19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction correct: 0.596\n"
     ]
    }
   ],
   "source": [
    "frac = nn.check_accuracy()\n",
    "print(f\"fraction correct: {frac}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "403be387-284d-496f-b0d5-c45046d00c64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction correct: 0.517\n"
     ]
    }
   ],
   "source": [
    "err = []\n",
    "npts = 1000\n",
    "n_right = 0\n",
    "for k in range(npts):\n",
    "    model = ModelDataCategorical()\n",
    "    y_nn = nn.predict(model)\n",
    "    if y_nn == model.y:\n",
    "        n_right += 1\n",
    "    err.append(abs(y_nn - model.y))\n",
    "    \n",
    "print(f\"fraction correct: {n_right / npts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bf7fd-4f34-4abc-ad8a-c7764ad5529e",
   "metadata": {},
   "source": [
    "Now we can get 50-70% accuracy by varying the size of the hidden layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
