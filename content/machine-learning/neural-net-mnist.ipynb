{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c67d5ca-23d3-4191-8b80-32ea22ab9473",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example: Character Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2010c9-2524-44e8-b35f-84817bd3c1f2",
   "metadata": {},
   "source": [
    "We'll apply the ideas we just learned to a neural network that does character recognition using the [MNIST database](https://en.wikipedia.org/wiki/MNIST_database).  This\n",
    "is a set of handwritten digits (0&ndash;9) represented as a 28&times;28 pixel grayscale image.\n",
    "\n",
    "There are 2 datasets, the training set with 60,000 images and the test set with 10,000 images.  We will use a version of the data that is provided as CSV files:\n",
    "\n",
    "* [mnist_train.csv.zip](mnist_train.csv.zip)\n",
    "* [mnist_test.csv.zip](mnist_test.csv.zip)\n",
    "\n",
    "Each line of these files provides the answer (i.e., what the digit is) as the first column and then the next 784 columns are the pixel values.\n",
    "\n",
    "We'll write a class to managed this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602ba5fc-1e82-4a16-a492-783c9f3349d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997231-daa6-490b-81cf-701114f2124e",
   "metadata": {},
   "source": [
    "A `TrainingDigit` provides a scaled floating point representation of the image as a 1D array (`.scaled`) as well as the correct answer (`.num`)\n",
    "and categorical data that is used to represent the answer from the neural network&mdash;a 10 element array of 1s and 0s.  It also provides a method to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058297be-b282-42ff-af6d-7f5522014cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainingDigit:\n",
    "    \"\"\"a handwritten digit from the MNIST training set\"\"\"\n",
    "\n",
    "    def __init__(self, raw_string):\n",
    "        \"\"\"we feed this a single line from the MNIST data set\"\"\"\n",
    "        self.raw_string = raw_string\n",
    "\n",
    "        # make the data range from 0.01 to 1.00\n",
    "        _tmp = raw_string.split(\",\")\n",
    "        self.scaled = np.asfarray(_tmp[1:])/255.0 * 0.99 + 0.01\n",
    "\n",
    "        # the correct answer\n",
    "        self.num = int(_tmp[0])\n",
    "\n",
    "        # the output for the NN as a bit array -- make this lie in [0.01, 0.99]\n",
    "        self.out = np.zeros(10) + 0.01\n",
    "        self.out[self.num] = 0.99\n",
    "\n",
    "    def plot(self, output=None):\n",
    "        \"\"\"plot the digit\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(self.scaled.reshape((28, 28)),\n",
    "                  cmap=\"Greys\", interpolation=\"nearest\")\n",
    "        if output is not None:\n",
    "            dstr = [f\"{n}: {v:6.4f}\" for n, v in enumerate(output)]\n",
    "            ostr = f\"correct digit: {self.num}\\n\"\n",
    "            ostr += \"  \".join(dstr[0:5]) + \"\\n\" + \"  \".join(dstr[5:])\n",
    "            plt.title(f\"{ostr}\", fontsize=\"x-small\")\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08a5fe-7628-4be4-b4c0-29fd17af436e",
   "metadata": {},
   "source": [
    "An `UnknownDigit` is like a `TrainingDigit` but it also provides a method to check if our prediction from the network is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab821e68-4bf9-491f-a053-8f12a29c0309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnknownDigit(TrainingDigit):\n",
    "    \"\"\"A digit from the MNIST test database.  This provides a method to\n",
    "    compare a NN result to the correct answer\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_string):\n",
    "        super().__init__(raw_string)\n",
    "        self.out = None\n",
    "\n",
    "    def check_output(self, out):\n",
    "        \"\"\"given the output array from the NN, return True if it is\n",
    "        correct for this digit\"\"\"\n",
    "        guess = np.argmax(out)\n",
    "        return guess == self.num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180eb3b-03e9-4764-8121-19cfb290c56a",
   "metadata": {},
   "source": [
    "Now we'll read in the data and store the training and test sets in separate lists.  We store the files as zipped files, so we need to unzip first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ca2a15-5603-40d1-ab29-b8d4e9e9bd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6d7158-b175-476f-9339-9661ec246e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "with zipfile.ZipFile(\"mnist_train.csv.zip\") as zf:\n",
    "    with zf.open(\"mnist_train.csv\") as f:\n",
    "        for line in f:\n",
    "            training_set.append(TrainingDigit(line.decode(\"utf8\").strip(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce81c1b-16a6-4296-ad1a-5f5f24f5a33d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227a8fa3-d416-456b-baa3-3fcb88c0d963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = []\n",
    "with zipfile.ZipFile(\"mnist_test.csv.zip\") as zf:\n",
    "    with zf.open(\"mnist_test.csv\") as f:\n",
    "        for line in f:\n",
    "            test_set.append(UnknownDigit(line.decode(\"utf8\").strip(\"\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4776971-aa23-4a3f-a987-dadd67c1c171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2c893-ac12-46ba-a238-0754f78b74ad",
   "metadata": {},
   "source": [
    "Let's look at the first digit in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d30551e-800d-41e8-94f5-29a26bb9b21a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = training_set[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae93c8-4669-4af2-a181-471ba207bd0a",
   "metadata": {},
   "source": [
    "Here's what the scaled pixel values look like&mdash;this is what will be fed into the network as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298da442-1a0f-4b06-85f7-dd43fb41d26f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.02164706, 0.07988235, 0.07988235,\n",
       "       0.07988235, 0.49917647, 0.538     , 0.68941176, 0.11094118,\n",
       "       0.65447059, 1.        , 0.96894118, 0.50305882, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.12647059, 0.14976471, 0.37494118, 0.60788235,\n",
       "       0.67      , 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.88352941, 0.67776471, 0.99223529, 0.94952941,\n",
       "       0.76705882, 0.25847059, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.20023529, 0.934     ,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.98447059, 0.37105882,\n",
       "       0.32835294, 0.32835294, 0.22741176, 0.16141176, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.07988235, 0.86023529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.77870588, 0.71658824,\n",
       "       0.96894118, 0.94564706, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.32058824, 0.61564706, 0.42541176, 0.99223529, 0.99223529,\n",
       "       0.80588235, 0.05270588, 0.01      , 0.17694118, 0.60788235,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.06435294,\n",
       "       0.01388235, 0.60788235, 0.99223529, 0.35941176, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.54964706,\n",
       "       0.99223529, 0.74764706, 0.01776471, 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.05270588, 0.74764706, 0.99223529,\n",
       "       0.28176471, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.14588235, 0.94564706, 0.88352941, 0.63117647,\n",
       "       0.42929412, 0.01388235, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.32447059, 0.94176471, 0.99223529, 0.99223529, 0.472     ,\n",
       "       0.10705882, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.18470588,\n",
       "       0.73211765, 0.99223529, 0.99223529, 0.59235294, 0.11482353,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.07211765, 0.37105882,\n",
       "       0.98835294, 0.99223529, 0.736     , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.97670588, 0.99223529,\n",
       "       0.97670588, 0.25847059, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.18858824, 0.51470588,\n",
       "       0.72047059, 0.99223529, 0.99223529, 0.81364706, 0.01776471,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.16141176,\n",
       "       0.58458824, 0.89905882, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.98058824, 0.71658824, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.10317647, 0.45258824, 0.868     , 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.79035294, 0.31282353, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.09929412, 0.26623529, 0.83694118, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.77870588, 0.32447059,\n",
       "       0.01776471, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.07988235, 0.67388235, 0.86023529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.99223529, 0.76705882,\n",
       "       0.32058824, 0.04494118, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.22352941, 0.67776471,\n",
       "       0.88741176, 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.95729412, 0.52635294, 0.05270588, 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.538     , 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.83305882, 0.53411765, 0.52247059, 0.07211765, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0].scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd79c9-d1bb-400c-9025-a416b42877c1",
   "metadata": {},
   "source": [
    "and here's what the categorical output looks like&mdash;this will be what we expect the network to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3439d9-8aa3-44f6-8b11-08ac2b2f3f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0].out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2379b-5070-43b8-9bf3-cbd1ecb8eda9",
   "metadata": {},
   "source": [
    "Now we can write our neural network class.  We will include a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a31b371a-5711-4cfd-9b6a-735f7cd1f2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"A neural network class with a single hidden layer.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size=1, output_size=1, hidden_layer_size=1):\n",
    "\n",
    "        # the number of nodes/neurons on the output layer\n",
    "        self.N_out = output_size\n",
    "\n",
    "        # the number of nodes/neurons on the input layer\n",
    "        self.N_in = input_size\n",
    "\n",
    "        # the number of nodes/neurons on the hidden layer\n",
    "        self.N_hidden = hidden_layer_size\n",
    "\n",
    "        # we will initialize the weights with Gaussian normal random\n",
    "        # numbers centered on 0 with a width of 1/sqrt(n), where n is\n",
    "        # the length of the input state\n",
    "\n",
    "        # A is the set of weights between the hidden layer and output layer\n",
    "        self.A = np.random.normal(0.0, 1.0/np.sqrt(self.N_hidden), (self.N_out, self.N_hidden))\n",
    "\n",
    "        # B is the set of weights between the input layer and hidden layer\n",
    "        self.B = np.random.normal(0.0, 1.0/np.sqrt(self.N_in), (self.N_hidden, self.N_in))\n",
    "\n",
    "    def g(self, xi):\n",
    "        \"\"\"our sigmoid function that operates on the hidden layer\"\"\"\n",
    "        return 1.0/(1.0 + np.exp(-xi))\n",
    "\n",
    "    def train(self, training_data, n_epochs=1, learning_rate=0.1):\n",
    "        \"\"\"Train the neural network by doing gradient descent with back\n",
    "        propagation to set the matrix elements in B (the weights\n",
    "        between the input and hidden layer) and A (the weights between\n",
    "        the hidden layer and output layer)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"size of training data = {len(training_data)}\")\n",
    "        \n",
    "        for i in range(n_epochs):\n",
    "            print(f\"epoch {i+1} of {n_epochs}\")\n",
    "\n",
    "            for n, model in enumerate(training_data):\n",
    "\n",
    "                # make the input and output data one-dimensional\n",
    "                x = model.scaled.reshape(self.N_in, 1)\n",
    "                y = model.out.reshape(self.N_out, 1)\n",
    "\n",
    "                # propagate the input through the network\n",
    "                z_tilde = self.g(self.B @ x)\n",
    "                z = self.g(self.A @ z_tilde)\n",
    "\n",
    "                # compute the errors (backpropagate to the hidden layer)\n",
    "                e = z - y\n",
    "                e_tilde = self.A.T @ e\n",
    "\n",
    "                # corrections\n",
    "                dA = -2 * learning_rate * e * z * (1 - z) @ z_tilde.T\n",
    "                dB = -2 * learning_rate * e_tilde * z_tilde * (1 - z_tilde) @ x.T\n",
    "\n",
    "                self.A[:, :] += dA\n",
    "                self.B[:, :] += dB\n",
    "\n",
    "    def predict(self, model):\n",
    "        \"\"\" predict the outcome using our trained matrix A \"\"\"\n",
    "        y = self.g(self.A @ (self.g(self.B @ model.scaled)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c83b94-7916-4a95-a96b-01c604d28bcc",
   "metadata": {},
   "source": [
    "Create our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7179f852-99ea-4617-b783-94786db0630b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = len(training_set[0].scaled)\n",
    "output_size = len(training_set[0].out)\n",
    "net = NeuralNetwork(input_size=input_size, output_size=output_size, hidden_layer_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccac8d-f433-4849-81d3-090403d1b403",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a8fd94-6b5a-4ab6-98d4-a51220071b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data = 60000\n",
      "epoch 1 of 5\n",
      "epoch 2 of 5\n",
      "epoch 3 of 5\n",
      "epoch 4 of 5\n",
      "epoch 5 of 5\n"
     ]
    }
   ],
   "source": [
    "net.train(training_set, n_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba63f6-d0a1-4d07-8323-815b4dc9559c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's see what our accuracy rate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b09592-d2f2-4665-bb44-bbcf5ae51c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.949\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for model in test_set:\n",
    "    res = net.predict(model)\n",
    "    if model.check_output(res):\n",
    "        n_correct += 1\n",
    "\n",
    "print(f\"accuracy is {n_correct / len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f568d6-6c5d-4676-b41f-a5a4b6295036",
   "metadata": {},
   "source": [
    "So we are about 94% accurate.  We can try to improve this by training with more epochs or using a bigger hidden layer.  We might also try experimenting with [other activation functions](https://en.wikipedia.org/wiki/Activation_function#Table_of_activation_functions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
