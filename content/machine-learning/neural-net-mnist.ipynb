{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c67d5ca-23d3-4191-8b80-32ea22ab9473",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Writing Our Own Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2010c9-2524-44e8-b35f-84817bd3c1f2",
   "metadata": {},
   "source": [
    "We'll apply the ideas we just learned to a neural network that does character recognition using the [MNIST database](https://en.wikipedia.org/wiki/MNIST_database#:~:text=The%20MNIST%20database%20(Modified%20National,the%20field%20of%20machine%20learning.).  This\n",
    "is a set of handwritten digits (0&ndash;9) represented as a 28&times;28 pixel grayscale image.\n",
    "\n",
    "There are 2 datasets, the training set with 60,000 images and the test set with 10,000 images.  We will use a version of the data that is provided as CSV files:\n",
    "\n",
    "* [mnist_train.csv](mnist_train.csv)\n",
    "* [mnist_test.csv](mnist_test.csv)\n",
    "\n",
    "Each line of these files provides the answer (i.e., what the digit is) as the first column and then the next 784 columns are the pixel values.\n",
    "\n",
    "We'll write a class to managed this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602ba5fc-1e82-4a16-a492-783c9f3349d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80997231-daa6-490b-81cf-701114f2124e",
   "metadata": {},
   "source": [
    "A `TrainingDigit` provides a scaled floating point representation of the image as a 1D array (`.scaled`) as well as the correct answer (`.num`)\n",
    "and categorical data that is used to represent the answer from the neural network&mdash;a 10 element array of 1s and 0s.  It also provides a method to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "058297be-b282-42ff-af6d-7f5522014cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainingDigit:\n",
    "    \"\"\"a handwritten digit from the MNIST training set\"\"\"\n",
    "\n",
    "    def __init__(self, raw_string):\n",
    "        \"\"\"we feed this a single line from the MNIST data set\"\"\"\n",
    "        self.raw_string = raw_string\n",
    "\n",
    "        # make the data range from 0.01 to 1.00\n",
    "        _tmp = raw_string.split(\",\")\n",
    "        self.scaled = np.asfarray(_tmp[1:])/255.0 * 0.99 + 0.01\n",
    "\n",
    "        # the correct answer\n",
    "        self.num = int(_tmp[0])\n",
    "\n",
    "        # the output for the NN as a bit array -- make this lie in [0.01, 0.99]\n",
    "        self.out = np.zeros(10) + 0.01\n",
    "        self.out[self.num] = 0.99\n",
    "\n",
    "    def plot(self, output=None):\n",
    "        \"\"\"plot the digit\"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(self.scaled.reshape((28, 28)),\n",
    "                  cmap=\"Greys\", interpolation=\"nearest\")\n",
    "        if output is not None:\n",
    "            dstr = [f\"{n}: {v:6.4f}\" for n, v in enumerate(output)]\n",
    "            ostr = f\"correct digit: {self.num}\\n\"\n",
    "            ostr += \"  \".join(dstr[0:5]) + \"\\n\" + \"  \".join(dstr[5:])\n",
    "            plt.title(f\"{ostr}\", fontsize=\"x-small\")\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08a5fe-7628-4be4-b4c0-29fd17af436e",
   "metadata": {},
   "source": [
    "An `UnknownDigit` is like a `TrainingDigit` but it also provides a method to check if our prediction from the network is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab821e68-4bf9-491f-a053-8f12a29c0309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnknownDigit(TrainingDigit):\n",
    "    \"\"\"A digit from the MNIST test database.  This provides a method to\n",
    "    compare a NN result to the correct answer\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_string):\n",
    "        super().__init__(raw_string)\n",
    "        self.out = None\n",
    "\n",
    "    def check_output(self, out):\n",
    "        \"\"\"given the output array from the NN, return True if it is\n",
    "        correct for this digit\"\"\"\n",
    "        guess = np.argmax(out)\n",
    "        return guess == self.num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180eb3b-03e9-4764-8121-19cfb290c56a",
   "metadata": {},
   "source": [
    "Now we'll read in the data and store the training and test sets in separate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f6d7158-b175-476f-9339-9661ec246e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_set = []\n",
    "with open(\"mnist_train.csv\") as f:\n",
    "    for line in f:\n",
    "        training_set.append(TrainingDigit(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dce81c1b-16a6-4296-ad1a-5f5f24f5a33d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "227a8fa3-d416-456b-baa3-3fcb88c0d963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_set = []\n",
    "with open(\"mnist_test.csv\") as f:\n",
    "    for line in f:\n",
    "        test_set.append(UnknownDigit(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4776971-aa23-4a3f-a987-dadd67c1c171",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2c893-ac12-46ba-a238-0754f78b74ad",
   "metadata": {},
   "source": [
    "Let's look at the first digit in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d30551e-800d-41e8-94f5-29a26bb9b21a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = training_set[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae93c8-4669-4af2-a181-471ba207bd0a",
   "metadata": {},
   "source": [
    "Here's what the scaled pixel values look like&mdash;this is what will be fed into the network as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "298da442-1a0f-4b06-85f7-dd43fb41d26f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.02164706, 0.07988235, 0.07988235,\n",
       "       0.07988235, 0.49917647, 0.538     , 0.68941176, 0.11094118,\n",
       "       0.65447059, 1.        , 0.96894118, 0.50305882, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.12647059, 0.14976471, 0.37494118, 0.60788235,\n",
       "       0.67      , 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.88352941, 0.67776471, 0.99223529, 0.94952941,\n",
       "       0.76705882, 0.25847059, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.20023529, 0.934     ,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.98447059, 0.37105882,\n",
       "       0.32835294, 0.32835294, 0.22741176, 0.16141176, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.07988235, 0.86023529, 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.77870588, 0.71658824,\n",
       "       0.96894118, 0.94564706, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.32058824, 0.61564706, 0.42541176, 0.99223529, 0.99223529,\n",
       "       0.80588235, 0.05270588, 0.01      , 0.17694118, 0.60788235,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.06435294,\n",
       "       0.01388235, 0.60788235, 0.99223529, 0.35941176, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.54964706,\n",
       "       0.99223529, 0.74764706, 0.01776471, 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.05270588, 0.74764706, 0.99223529,\n",
       "       0.28176471, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.14588235, 0.94564706, 0.88352941, 0.63117647,\n",
       "       0.42929412, 0.01388235, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.32447059, 0.94176471, 0.99223529, 0.99223529, 0.472     ,\n",
       "       0.10705882, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.18470588,\n",
       "       0.73211765, 0.99223529, 0.99223529, 0.59235294, 0.11482353,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.07211765, 0.37105882,\n",
       "       0.98835294, 0.99223529, 0.736     , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.97670588, 0.99223529,\n",
       "       0.97670588, 0.25847059, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.18858824, 0.51470588,\n",
       "       0.72047059, 0.99223529, 0.99223529, 0.81364706, 0.01776471,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.16141176,\n",
       "       0.58458824, 0.89905882, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.98058824, 0.71658824, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.10317647, 0.45258824, 0.868     , 0.99223529, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.79035294, 0.31282353, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.09929412, 0.26623529, 0.83694118, 0.99223529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.77870588, 0.32447059,\n",
       "       0.01776471, 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.07988235, 0.67388235, 0.86023529,\n",
       "       0.99223529, 0.99223529, 0.99223529, 0.99223529, 0.76705882,\n",
       "       0.32058824, 0.04494118, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.22352941, 0.67776471,\n",
       "       0.88741176, 0.99223529, 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.95729412, 0.52635294, 0.05270588, 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.538     , 0.99223529, 0.99223529, 0.99223529,\n",
       "       0.83305882, 0.53411765, 0.52247059, 0.07211765, 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0].scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd79c9-d1bb-400c-9025-a416b42877c1",
   "metadata": {},
   "source": [
    "and here's what the categorical output looks like&mdash;this will be what we expect the network to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb3439d9-8aa3-44f6-8b11-08ac2b2f3f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0].out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2379b-5070-43b8-9bf3-cbd1ecb8eda9",
   "metadata": {},
   "source": [
    "Now we can write our neural network class.  We will include a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a31b371a-5711-4cfd-9b6a-735f7cd1f2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"A neural network class with a single hidden layer.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size=1, output_size=1, hidden_layer_size=1):\n",
    "\n",
    "        # the number of nodes/neurons on the output layer\n",
    "        self.m = output_size\n",
    "\n",
    "        # the number of nodes/neurons on the input layer\n",
    "        self.n = input_size\n",
    "\n",
    "        # the number of nodes/neurons on the hidden layer\n",
    "        self.k = hidden_layer_size\n",
    "\n",
    "        # we will initialize the weights with Gaussian normal random\n",
    "        # numbers centered on 0 with a width of 1/sqrt(n), where n is\n",
    "        # the length of the input state\n",
    "\n",
    "        # A is the set of weights between the hidden layer and output layer\n",
    "        self.A = np.random.normal(0.0, 1.0/np.sqrt(self.k), (self.m, self.k))\n",
    "\n",
    "        # B is the set of weights between the input layer and hidden layer\n",
    "        self.B = np.random.normal(0.0, 1.0/np.sqrt(self.n), (self.k, self.n))\n",
    "\n",
    "    def g(self, p):\n",
    "        \"\"\"our sigmoid function that operates on the hidden layer\"\"\"\n",
    "        return 1.0/(1.0 + np.exp(-p))\n",
    "\n",
    "    def train(self, training_data, n_epochs=1, learning_rate=0.1):\n",
    "        \"\"\"Train the neural network by doing gradient descent with back\n",
    "        propagation to set the matrix elements in B (the weights\n",
    "        between the input and hidden layer) and A (the weights between\n",
    "        the hidden layer and output layer)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"size of training data = {len(training_data)}\")\n",
    "        \n",
    "        for i in range(n_epochs):\n",
    "            print(f\"epoch {i+1} of {n_epochs}\")\n",
    "\n",
    "            for n, model in enumerate(training_data):\n",
    "\n",
    "                # make the input and output data one-dimensional\n",
    "                x = model.scaled.reshape(self.n, 1)\n",
    "                y = model.out.reshape(self.m, 1)\n",
    "\n",
    "                # propagate the input through the network\n",
    "                z_tilde = self.g(self.B @ x)\n",
    "                z = self.g(self.A @ z_tilde)\n",
    "\n",
    "                # compute the errors (backpropagate to the hidden layer)\n",
    "                e = z - y\n",
    "                e_tilde = self.A.T @ e\n",
    "\n",
    "                # corrections\n",
    "                dA = -2 * learning_rate * e * z*(1-z) @ z_tilde.T\n",
    "                dB = -2 * learning_rate * e_tilde * z_tilde*(1-z_tilde) @ x.T\n",
    "\n",
    "                self.A[:, :] += dA\n",
    "                self.B[:, :] += dB\n",
    "\n",
    "    def predict(self, model):\n",
    "        \"\"\" predict the outcome using our trained matrix A \"\"\"\n",
    "        y = self.g(self.A @ (self.g(self.B @ model.scaled)))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c83b94-7916-4a95-a96b-01c604d28bcc",
   "metadata": {},
   "source": [
    "Create our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7179f852-99ea-4617-b783-94786db0630b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = len(training_set[0].scaled)\n",
    "output_size = len(training_set[0].out)\n",
    "net = NeuralNetwork(input_size=input_size, output_size=output_size, hidden_layer_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ccac8d-f433-4849-81d3-090403d1b403",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84a8fd94-6b5a-4ab6-98d4-a51220071b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data = 60000\n",
      "epoch 1 of 5\n",
      "epoch 2 of 5\n",
      "epoch 3 of 5\n",
      "epoch 4 of 5\n",
      "epoch 5 of 5\n"
     ]
    }
   ],
   "source": [
    "net.train(training_set, n_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba63f6-d0a1-4d07-8323-815b4dc9559c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's see what our accuracy rate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05b09592-d2f2-4665-bb44-bbcf5ae51c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9465\n"
     ]
    }
   ],
   "source": [
    "n_correct = 0\n",
    "for model in test_set:\n",
    "    res = net.predict(model)\n",
    "    if model.check_output(res):\n",
    "        n_correct += 1\n",
    "\n",
    "print(f\"accuracy is {n_correct / len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccf17b-419e-45db-902e-e7bd2ea3e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
